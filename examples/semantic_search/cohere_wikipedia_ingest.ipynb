{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingesting Wikipedia into ApertureDB\n",
    "\n",
    "First we need to install a few libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet aperturedb langchain langchain-community langchainhub datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "We use the [Hugging Face Datasets library](https://huggingface.co/docs/datasets/en/index) to load a dataset provided by [Cohere](https://cohere.com/).\n",
    "This contains the content of [Wikipedia](https://www.wikipedia.org/) (from November 2023), already cleaned up, chunked, and with pre-generated embeddings.\n",
    "\n",
    "We've included a restriction on the number of documents in order to speed you through the notebook and make sure that you don't run out of RAM.\n",
    "Feel free to comment out that line and take coffee breaks instead.\n",
    "\n",
    "This may take a minute to run.  You might see a warning about `HF_TOKEN` when you run this code.  This is harmless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "646424\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "lang = \"simple\" # Smaller than the \"en\" dataset\n",
    "full_dataset = load_dataset(\"Cohere/wikipedia-2023-11-embed-multilingual-v3\", lang)\n",
    "dataset = full_dataset[\"train\"]\n",
    "print(len(dataset))\n",
    "N_DOCS = 10000\n",
    "dataset = dataset.select(range(N_DOCS)) # Comment this line out to use the full dataset\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap these embeddings for LangChain\n",
    "\n",
    "LangChain expects a class that will create embeddings on-the-fly, but we have a set of pre-computed embeddings.\n",
    "This is a wrapper class that bridges the gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain_core.embeddings\n",
    "try:\n",
    "    from typing import override\n",
    "except ImportError:\n",
    "    def override(func):\n",
    "        return func\n",
    "\n",
    "class PrecomputedEmbeddings(langchain_core.embeddings.embeddings.Embeddings):\n",
    "    @classmethod\n",
    "    def from_dataset(class_, dataset):\n",
    "        result = class_()\n",
    "        result.index = {doc['text']: doc['emb'] for doc in dataset}\n",
    "        return result\n",
    "\n",
    "    @override\n",
    "    def embed_documents(self, texts):\n",
    "        # Will throw if text is not in index\n",
    "        return [self.index[text] for text in texts]\n",
    "\n",
    "    @override\n",
    "    def embed_query(self, query):\n",
    "        # Will throw if text is not in index\n",
    "        return self.index[query]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our LangChain embeddings object that will work on the Wikipedia corpus.\n",
    "\n",
    "If you elected not to use a subset of documents, this will take "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = PrecomputedEmbeddings.from_dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to ApertureDB\n",
    "\n",
    "For the next part, we need access to a specific ApertureDB instance.\n",
    "There are several ways to set this up.\n",
    "The code provided here will accept ApertureDB connection information as a JSON string.\n",
    "See our [Configuration](https://docs.aperturedata.io/Setup/client/configuration) help page for more options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! adb config create rag --from-json --active "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a LangChain vectorstore using ApertureDB.\n",
    "We use the default client configuration that we have already set up.\n",
    "\n",
    "If you want to create more than one version of the embeddings, then change the `DESCRIPTOR_SET` name.\n",
    "\n",
    "We know that the Cohere embeddings are 1024-dimensional.\n",
    "See [AddDescriptorSet](https://docs.aperturedata.io/query_language/Reference/descriptor_commands/desc_set_commands/AddDescriptorSet) for more information about selecting an engine and metric.\n",
    "\n",
    "We use the embeddings object we created above, which will be used when we add documents to the vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import ApertureDB\n",
    "\n",
    "DESCRIPTOR_SET = 'cohere_wikipedia_2023_11_embed_multilingual_v3'\n",
    "\n",
    "vectorstore = ApertureDB(\n",
    "    embeddings=embeddings,\n",
    "    descriptor_set=DESCRIPTOR_SET,\n",
    "    dimensions=1024,\n",
    "    engine=\"HNSW\",\n",
    "    metric=\"CS\",\n",
    "    log_level=\"INFO\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert from Hugging Face to LangChain\n",
    "\n",
    "Hugging Face documents are not exactly the same as LangChain documents so we have to convert them.\n",
    "This will take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "def hugging_face_document_to_langchain(doc):\n",
    "    return Document(page_content=doc[\"text\"], metadata={\"url\": doc[\"url\"], \"title\": doc[\"title\"], \"id\": doc[\"_id\"]})\n",
    "\n",
    "\n",
    "docs = [hugging_face_document_to_langchain(doc) for doc in dataset]\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the documents into the vectorstore\n",
    "\n",
    "Finally, we come to the part where we load the documents into the vectorstore.\n",
    "Again, this will take a little while to run.\n",
    "\n",
    "The full process takes a while, so we've restricted it here to a few thousand documents so you can progress through the notebook.\n",
    "You can remove this limit and go for lunch instead.\n",
    "\n",
    "Once you add the documents, your ApertureDB instance will be hard at work building a high-performance index for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = vectorstore.add_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out how many documents are in our vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"_count\": 10000,\n",
      "    \"_dimensions\": 1024,\n",
      "    \"_engines\": [\n",
      "      \"HNSW\"\n",
      "    ],\n",
      "    \"_metrics\": [\n",
      "      \"CS\"\n",
      "    ],\n",
      "    \"_name\": \"cohere_wikipedia_2023_11_embed_multilingual_v3\",\n",
      "    \"_uniqueid\": \"2.0.80\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps([ d for d in ApertureDB.list_vectorstores() if d['_name'] == DESCRIPTOR_SET ], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy up\n",
    "\n",
    "If you want to tidy up and restore your ApertureDB instance to before, you can delete the vectorstore.\n",
    "\n",
    "We've deliberately left this next box not executable so you can go on to use your database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ApertureDB.delete_vectorstore(DESCRIPTOR_SET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "Next you want to use this vectorstore to drive a RAG (Retrieval-Augmented Generation) chain.\n",
    "\n",
    "See [Building a RAG Chain from Wikipedia](https://docs.aperturedata.io/HowToGuides/Applications/cohere_wikipedia_rag)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further information\n",
    "\n",
    "* [LangChain vectorstore integration](https://python.langchain.com/api_reference/community/vectorstores/langchain_community.vectorstores.aperturedb.ApertureDB.html)\n",
    "* [ApertureDB documentation website](https://docs.aperturedata.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
